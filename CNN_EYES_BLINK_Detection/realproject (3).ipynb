{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z42V8XYiNikn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import glob\n",
        "import cv2\n",
        "import shutil\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "from google.colab import files # 데이터 불러오기\n",
        "file_uploaded=files.upload()   # 데이터 불러오기: chap05/data/catndog.zip 파일 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGmFnj1PNk7-"
      },
      "outputs": [],
      "source": [
        "!unzip eyes.zip -d eyes/    #eyes 폴더 만들어 압축 풀기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9oVUtnociS6"
      },
      "outputs": [],
      "source": [
        "data_path = 'eyes/train/' # train 데이터 셋\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.Resize([256, 256]),\n",
        "                    transforms.RandomResizedCrop(224),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor(),\n",
        "                ])\n",
        "train_dataset = torchvision.datasets.ImageFolder(\n",
        "    data_path,\n",
        "    transform=transform\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=8,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(len(train_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6QUGLRacp3L"
      },
      "outputs": [],
      "source": [
        "test_path = 'eyes/test/'\n",
        "\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.Resize(224),\n",
        "                    transforms.CenterCrop(224),\n",
        "                    transforms.ToTensor(),\n",
        "                ])\n",
        "test_dataset = torchvision.datasets.ImageFolder(\n",
        "    root=test_path,\n",
        "    transform=transform\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=8,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYdAHYR3cto6"
      },
      "outputs": [],
      "source": [
        "samples, labels = next(iter(train_loader))\n",
        "classes = {0:'close',1:'on'}\n",
        "fig = plt.figure(figsize=(16,24))\n",
        "for i in range(12):\n",
        "    a = fig.add_subplot(4,6,i+1)\n",
        "    a.set_title(classes[labels[i].item()])\n",
        "    a.axis('on')\n",
        "    a.imshow(np.transpose(samples[i].numpy(), (1,2,0)))\n",
        "plt.subplots_adjust(bottom=0.2, top=0.6, hspace=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v6yBELuc0CK"
      },
      "outputs": [],
      "source": [
        "class EyesCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EyesCNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=7, padding=1),  #224 -7 +2 /1 +1      220\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # 32 * 220 -2 /2 +1  110\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5), # 42 * 110-5 /1 +1 = 106\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)  # 106-2/2+1 64* 53\n",
        "        )\n",
        "        # 64*53\n",
        "#        self.layer3 = nn.Sequential(\n",
        "#           nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=2), #64* 53-3 +4 /1 +1 =55\n",
        "#           nn.BatchNorm2d(64),\n",
        "#           nn.ReLU(),\n",
        "#           nn.MaxPool2d(kernel_size=3,stride=2) #55-3 /2 +1  27\n",
        "#        )\n",
        "#        self.layer4 = nn.Sequential(\n",
        "#           nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1,padding=2), #64* 27-1+4/1 +1 31\n",
        "#            nn.BatchNorm2d(64),\n",
        "#            nn.ReLU(),\n",
        "#            nn.MaxPool2d(kernel_size=3,stride=4) #64* 31 - 3/4 +1\n",
        "#        )\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=64*53*53, out_features=600)\n",
        "        self.drop = nn.Dropout2d(0.25)\n",
        "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
        "        self.fc3 = nn.Linear(in_features=120, out_features=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "#        out = self.layer3(out)\n",
        "#        out = self.layer4(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.drop(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbsXJMdCc5Tx"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "learning_rate = 0.001;\n",
        "model = EyesCNN();\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss();\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate);\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dluQStqRc8Op"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, device, num_epochs=20, is_train=True):\n",
        "    since = time.time()\n",
        "    acc_history = []\n",
        "    loss_history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            model.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
        "\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "\n",
        "        acc_history.append(epoch_acc.item())\n",
        "        loss_history.append(epoch_loss)\n",
        "        torch.save(model.state_dict(), os.path.join('eyes/', '{0:0=2d}.pth'.format(epoch)))\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best Acc: {:4f}'.format(best_acc))\n",
        "    return acc_history, loss_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyYlPB8RdBOx"
      },
      "outputs": [],
      "source": [
        "train_acc_hist, train_loss_hist = train_model(model, train_loader, criterion, optimizer, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMz-0BZ2dEDC"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, dataloaders, device):\n",
        "    since = time.time()\n",
        "    acc_history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    saved_models = glob.glob('eyes/' + '*.pth')\n",
        "    saved_models.sort()\n",
        "    print('saved_model', saved_models)\n",
        "\n",
        "    for model_path in saved_models:\n",
        "        print('Loading model', model_path)\n",
        "\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "        model.to(device)\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            preds[preds >= 0.5] = 1\n",
        "            preds[preds < 0.5] = 0\n",
        "            running_corrects += preds.eq(labels).int().sum()\n",
        "\n",
        "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
        "        print('Acc: {:.4f}'.format(epoch_acc))\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "\n",
        "        acc_history.append(epoch_acc.item())\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Validation complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    return acc_history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGrgmUv2dKRC"
      },
      "outputs": [],
      "source": [
        "val_acc_hist = eval_model(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN TSNE\n",
        "actual = []\n",
        "deep_features = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        features = model(images)\n",
        "\n",
        "        deep_features += features.cpu().numpy().tolist()\n",
        "        actual += labels.cpu().numpy().tolist()\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "cluster = np.array(tsne.fit_transform(np.array(deep_features)))\n",
        "actual = np.array(actual)\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "name = ['close', 'on']\n",
        "for i, label in zip(range(2), name):\n",
        "    idx = np.where(actual == i)\n",
        "    plt.scatter(cluster[idx, 0], cluster[idx, 1], marker='.', label=label)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9HQX-DqJwO-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfW_1l9GdL1h"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_acc_hist)\n",
        "plt.plot(val_acc_hist)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train_Accuracy', 'Val_Accuracy'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Urwr3wj0dNnz"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss_hist)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train_Loss'])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}